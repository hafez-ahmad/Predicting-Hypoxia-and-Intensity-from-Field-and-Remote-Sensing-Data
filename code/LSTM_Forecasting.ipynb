{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ddd28ad4",
   "metadata": {},
   "source": [
    "# Hypoxia Forecasting with LSTM (t+1, t+7, t+10)\n",
    "\n",
    "Sequence classification using LSTM/GRU for short-horizon hypoxia prediction. This notebook focuses on end-to-end deep learning (TensorFlow/Keras) with sliding windows and horizon-specific targets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a66e4ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports & Config\n",
    "import os, numpy as np, pandas as pd\n",
    "from datetime import timedelta\n",
    "\n",
    "DATA_CSV = r\"C:\\\\Users\\\\hafez\\\\MSU\\\\Research\\\\msGOM\\\\mssound\\\\bloom\\\\data\\\\processed\\\\hypoxia_timeseries.csv\"\n",
    "DATE_COL, TARGET_COL = 'date', 'label'\n",
    "GROUP_COLS = ['lat','lon']\n",
    "FEATURE_COLS = [\n",
    "    'chlor_a','nflh','poc','sst','Rrs_412','Rrs_443','Rrs_469','Rrs_488',\n",
    "    'Rrs_531','Rrs_547','Rrs_555','Rrs_645','Rrs_667','Rrs_678'\n",
    "]\n",
    "\n",
    "try:\n",
    "    import tensorflow as tf\n",
    "    from tensorflow import keras\n",
    "    from tensorflow.keras import layers\n",
    "    print('TensorFlow', tf.__version__)\n",
    "except Exception as e:\n",
    "    raise SystemExit('Please install TensorFlow (pip install tensorflow) to run this notebook')\n",
    "\n",
    "# Load\n",
    "df = pd.read_csv(DATA_CSV)\n",
    "df[DATE_COL] = pd.to_datetime(df[DATE_COL])\n",
    "df = df.sort_values([*GROUP_COLS, DATE_COL]).reset_index(drop=True)\n",
    "\n",
    "# Basic imputation per pixel\n",
    "df[FEATURE_COLS] = df.groupby(GROUP_COLS)[FEATURE_COLS].apply(lambda g: g.ffill().bfill()).reset_index(level=GROUP_COLS, drop=True)\n",
    "\n",
    "# Normalization (global min-max)\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "df[[f'{c}_scaled' for c in FEATURE_COLS]] = scaler.fit_transform(df[FEATURE_COLS])\n",
    "FEATS = [f'{c}_scaled' for c in FEATURE_COLS]\n",
    "\n",
    "# Build sequences\n",
    "H_K = {1:2, 7:7, 10:10}\n",
    "\n",
    "def build_sequences(df_in: pd.DataFrame, k: int, h: int):\n",
    "    X_list, y_list = [], []\n",
    "    for _, g in df_in.groupby(GROUP_COLS):\n",
    "        g = g.sort_values(DATE_COL)\n",
    "        V = g[FEATS].values\n",
    "        y_arr = g[TARGET_COL].values.astype('int32')\n",
    "        for t in range(k, len(g) - h):\n",
    "            X_list.append(V[t-k:t, :])\n",
    "            y_list.append(y_arr[t + h])\n",
    "    return np.stack(X_list, axis=0), np.array(y_list)\n",
    "\n",
    "# Model factory\n",
    "def make_lstm(seq_len, n_feat):\n",
    "    model = keras.Sequential([\n",
    "        layers.Input(shape=(seq_len, n_feat)),\n",
    "        layers.Masking(mask_value=0.0),\n",
    "        layers.LSTM(64, return_sequences=False),\n",
    "        layers.Dropout(0.2),\n",
    "        layers.Dense(32, activation='relu'),\n",
    "        layers.Dropout(0.2),\n",
    "        layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    model.compile(optimizer=keras.optimizers.Adam(1e-3),\n",
    "                  loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "results = {}\n",
    "\n",
    "for h in [1,7,10]:\n",
    "    k = H_K[h]\n",
    "    print(f\"\\n=== LSTM t+{h} with k={k} ===\")\n",
    "    X, y = build_sequences(df, k=k, h=h)\n",
    "    n = len(y)\n",
    "    i_val, i_test = int(n*0.6), int(n*0.8)\n",
    "    X_tr, y_tr = X[:i_val], y[:i_val]\n",
    "    X_va, y_va = X[i_val:i_test], y[i_val:i_test]\n",
    "    X_te, y_te = X[i_test:], y[i_test:]\n",
    "\n",
    "    model = make_lstm(seq_len=k, n_feat=X.shape[-1])\n",
    "    cb = [keras.callbacks.EarlyStopping(patience=5, restore_best_weights=True)]\n",
    "    hist = model.fit(X_tr, y_tr, validation_data=(X_va, y_va),\n",
    "                     epochs=30, batch_size=256, callbacks=cb, verbose=1)\n",
    "\n",
    "    y_prob = model.predict(X_te, verbose=0).ravel()\n",
    "\n",
    "    # Metrics\n",
    "    from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, precision_score, recall_score\n",
    "    y_pred = (y_prob >= 0.5).astype(int)\n",
    "    metrics = {\n",
    "        'accuracy': float(accuracy_score(y_te, y_pred)),\n",
    "        'precision': float(precision_score(y_te, y_pred, zero_division=0)),\n",
    "        'recall': float(recall_score(y_te, y_pred, zero_division=0)),\n",
    "        'f1': float(f1_score(y_te, y_pred, zero_division=0)),\n",
    "        'roc_auc': float(roc_auc_score(y_te, y_prob)) if len(np.unique(y_te))>1 else None\n",
    "    }\n",
    "    print('Test metrics:', metrics)\n",
    "\n",
    "    # Save\n",
    "    out_dir = os.path.dirname(DATA_CSV)\n",
    "    save_path = os.path.join(out_dir, f'lstm_t+{h}.keras')\n",
    "    model.save(save_path)\n",
    "    results[h] = metrics\n",
    "\n",
    "print('\\nSummary:', results)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
